"""
Peragenome - db_handler.py
Created by: Angus Hilts
August 18, 2016

Summary:
    Collection of functions for building, loading, and manipulating a database.

Interface Description:
    create_db: string string -> string
    get_dat_field: string file -> string
    add_new_dataset: string string file listOf(String) -> string
"""

import os
import sys
import glob
import logging
import time
import csv_handler as csv

# create_db: string string -> string
# Description:
#   Creates files to store relevant information for the new database. This includes the following:
#       - .pfs.dat      Stores info relevant to the database
#       - .csv          Stores metadata pertaining to related databases (a single file will be created, but
#                           more may be added.
#   A string containing the path to the .pfs.dat file is returned
# Side effects:
#   New files will be created in the specified directory
# NOTE: This no longer creates a .csv on its own. The .csv file must be generated by adding a dataset to the
# file system.
def create_db(fs_root_dir, name):

    logging.info( "create_db: START" )

    try:
        if not os.path.exists( os.path.abspath(fs_root_dir) ):
            raise ValueError("the specified path could not be found")

        logging.info( "create_db: %s" % fs_root_dir )
        logging.info( "The path was found" )

        # Generate name for .pfs.dat file
        dat_filename = "%s.pfs.dat" % name
        dat_path = "%s/%s" % (fs_root_dir, dat_filename)
        dat_abs_path = os.path.abspath( dat_path )


        # Push some info to the log for debugging
        logging.debug("create_db: Paths were created")
        logging.debug("-dat_path: %s" % dat_abs_path)

        # create the dat file
        logging.info( "create_db: Generating .pfs.dat file" )
        with open (dat_abs_path, 'w+') as dat_file:
            dat_file.write( "name=\"%s\"\n" % name )
            dat_file.write( "created=\"%s\"\n" % time.strftime("%Y-%m-%d") )
            dat_file.write( "fs_root=\"%s\"\n" % os.path.abspath(fs_root_dir) )
            dat_file.write( "fs_dat=\"%s\"\n" % dat_abs_path )
            dat_file.write( "num_fs=\"%s\"" % "1" )     # just a default value, the number of associated
                                                        # datasets for the db.

        logging.info( "create_db: DONE" )
        return dat_abs_path

    except (ValueError,IOError) as err:
        err.args += (fs_root_dir, name,)
        logging.error( "create_db: " + str(err[:2]) )
        logging.error( "The database was not created" )

# get_dat_field: string file -> string
# Description:
#   Fetches the value associated with a field in the dat file
# NOTE: dat file fields should be of the form field_name="field_value"
def get_dat_field(field, dat_file):
    result = ""

    try:
        for line in dat_file:
            # check if current line is the field being looked for
            if line.split("=")[0] == field:
                    # trim the extra stuff away and return the field
                    # Fields are always in the form:
                    #   field_name="field_value"
                    result = line.split("=")[1]
                    result = result.split("\n")[0]
                    result = result.split("\"")[1]
                    return result
        raise LookupError("get_dat_field: field not found")
    except LookupError as err:
        err.args += (field, dat_file,)
        logging.warning( "get_dat_field: " + err[0] )
        logging.warning( "The value was not read from the file" )

# add_new_dataset: string string file listOf(String) -> string
# Description:
#   Checks the specified path, then adds an entry to the dat_file for the new data set.
#   If not specified, columns will use the default values. The first value in columns will be set to
#   be the "primary key"
#   Several files will be created:
#       - .ds.csv       .csv file for metadata associated with the database
# TODO: Deside what info should be held in the .dat file for each dataset
#   - .csv file location
#   - dataset name
#   - "primary key" for the table
def add_new_dataset(name, root_path, fs_dat_file, columns=["Identifier", "Name", "Seq. Method"]):
    try:
        # Create the filename for the new path
        csv_filename = os.path.join(root_path, name)
        

    except ValueError as err:
        err.args += (name, root_path, fs_dat_file,)
        logging.error( "add_new_dataset: " + str(err) )
        logging.error( "The dataset could not be added" )
    except IOError as err:
        # TODO: Update here
